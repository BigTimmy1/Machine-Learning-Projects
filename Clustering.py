# -*- coding: utf-8 -*-
"""CoAI2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/150OUl3a9YV8UlrUgR7h43Hhp9klSz6Fi
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from sklearn.cluster import KMeans
sns.set()

# Loading Dataset
data = pd.read_csv('country_data.csv')
data.head()

# Copy Data for Safety and Inspect Basic Stats
data_copy = data.copy()  # Keep the original data safe from manipulation
print("\nData Summary:")
display(data.describe(include='all'))

# Check for Missing Data
print("Missing Data Check:\n", data.isnull().sum())

# Data Visualization: Distribution of Features
# Plot each feature in a grid to examine the distributions
Xcolumns = ['child_mort', 'exports', 'health', 'imports', 'income', 'inflation', 'life_expec', 'total_fer', 'gdpp']
num_cols = len(Xcolumns)
num_rows = (num_cols - 1) // 3 + 1

fig, axs = plt.subplots(num_rows, 3, figsize=(15, 12))
fig.suptitle("Feature Distributions", fontsize=16)
for i, col in enumerate(Xcolumns):
    row, col_num = divmod(i, 3)
    sns.histplot(data_copy[col], kde=True, ax=axs[row, col_num])
    axs[row, col_num].set_title(col)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Scale Features for Clustering
X_scaled = preprocessing.scale(data_copy.drop(columns=['country']))

# Determine Optimal Number of Clusters with Elbow Method
sse = []
cluster_range = range(1, 11)
for k in cluster_range:
    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)
    kmeans.fit(data_copy.iloc[:,1:])
    sse.append(kmeans.inertia_)

plt.figure(figsize=(8, 5))
plt.plot(cluster_range, sse, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.show()

# Apply KMeans Clustering (using 4 clusters as a starting point from Elbow Plot)
kmeans_model = KMeans(n_clusters=4,n_init='auto', random_state=40)
data_copy['cluster_pred'] = kmeans_model.fit(X_scaled)

cluster_centers = kmeans_model.cluster_centers_
# print the centre positions of the clusters
centers = kmeans_model.cluster_centers_
print('Centroids:', centers, '\n')

from matplotlib.colors import Normalize

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.colors import Normalize
import numpy as np

# Assume these are the 3 features we're visualizing in 3D (adjust based on your dataset)
feature_1 = 'child_mort'
feature_2 = 'life_expec'
feature_3 = 'income'

# Extract the relevant columns for the 3D plot
X_plot = data_copy[[feature_1, feature_2, feature_3]].values

# Fit KMeans and get the cluster centers for plotting
kmeans_ = KMeans(n_clusters=4, random_state=42)
kmeans_.fit(X_scaled)
centers = kmeans_.cluster_centers_[:, :3]  # Get the first 3 dimensions of the cluster centers

# Visualize the result in a 3D plot
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection='3d')

# Normalization for color encoding based on the number of clusters
nm = Normalize(vmin=0, vmax=len(centers)-1)

# Scatter plot for the clustered data points
scatter1 = ax.scatter(X_plot[:, 0], X_plot[:, 1], X_plot[:, 2],
                      c=kmeans_.predict(X_scaled), s=50, cmap='plasma', norm=nm)

# Plot the centroids with cluster labels
for i in range(centers.shape[0]):
    ax.text(centers[i, 0], centers[i, 1], centers[i, 2],
            str(i), color='black',
            bbox=dict(boxstyle="round", facecolor='white', edgecolor='black'))

# Set the view angle
ax.azim = -60
ax.dist = 10
ax.elev = 10

# Label the axes using the feature names
ax.set_xlabel(feature_1)
ax.set_ylabel(feature_2)
ax.set_zlabel(feature_3)

# Add a legend for the clusters
legend1 = ax.legend(*scatter1.legend_elements(), loc="center left", title="Clusters")
ax.add_artist(legend1)

# Adjust layout and display the plot
fig.tight_layout(pad=-2.0)
plt.show()

# Cluster Analysis and Visualization
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=data_copy, x='child_mort', y='life_expec', hue='cluster_pred', palette='viridis', s=100, alpha=0.7
)
plt.xlabel('Child Mortality')
plt.ylabel('Life Expectancy')
plt.title('Clustering by Child Mortality and Life Expectancy')
plt.legend(title='Cluster')
plt.show()